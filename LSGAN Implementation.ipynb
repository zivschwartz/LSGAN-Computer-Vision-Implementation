{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSGAN Implementation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"B3pitfgOqGPE","colab_type":"code","colab":{}},"source":["import os\n","from os import listdir\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nxGHBftO8f60","colab_type":"text"},"source":[" Load things from our shared project repository"]},{"cell_type":"code","metadata":{"id":"FekvL1mJUYfG","colab_type":"code","outputId":"6a1a17e0-785f-4abf-ba10-9afcb38a1239","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE_DIR = ('drive/My Drive/LSGAN-Project')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PNtjNl52DEgR","colab_type":"code","outputId":"27867423-607c-4329-ad8f-2a4568a05a51","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["listdir(BASE_DIR + \"/data/\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['mnist', 'fashion-mnist', 'gan', 'our_gan', 'lsgan']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"TSGAqDA78b_O","colab_type":"text"},"source":["Parameters go here"]},{"cell_type":"code","metadata":{"id":"l0eAw7plAHr0","colab_type":"code","colab":{}},"source":["n_epochs = 200\n","batch_size = 64\n","lr = 0.0002\n","b1 = 0.5\n","b2 = 0.999\n","latent_dim = 1024\n","img_size = 32\n","channels = 1\n","sample_interval = 400"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RMXYs1lm7Pq6","colab_type":"code","colab":{}},"source":["img_shape = (channels, img_size, img_size)\n","\n","cuda = True if torch.cuda.is_available() else False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5QLWRdxhY8HD","colab_type":"code","outputId":"396e503e-2a2c-4cab-c8c9-48cf4a248478","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["int(np.prod(img_shape))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1024"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"QmZinmobWokF","colab_type":"text"},"source":["Make sure your runtime is set to GPU for this to be true"]},{"cell_type":"code","metadata":{"id":"WhVQdmqcVvjF","colab_type":"code","outputId":"d742669b-b816-4116-e6a9-da654e51e1f1","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cuda"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"93XIBhbezLzw","colab_type":"text"},"source":["# Our Implementation"]},{"cell_type":"markdown","metadata":{"id":"y7Gx8PnMG178","colab_type":"text"},"source":["Let's do this with architecture proposed in paper, except with LSGAN\n","\n","THIS IS OUR OWN CODE.\n","\n","**If I commented out a layer, it was because it was taking very long to train**"]},{"cell_type":"code","metadata":{"id":"OnvPhl98tVQ1","colab_type":"code","colab":{}},"source":["class Our_Generator(nn.Module):\n","    def __init__(self, batch_norm = True, momentum = 0.8):\n","        super(Our_Generator, self).__init__()\n","        \n","        self.init_size = img_size // 16\n","\n","        def linear_block(in_feat, out_feat, bn=batch_norm):\n","            layers = [nn.Linear(in_feat, out_feat)]\n","            if bn:\n","                layers.append(nn.BatchNorm1d(out_feat, momentum = momentum))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","        # as specified in paper\n","        def deconv_block(input_channels, output_channels, kernel_size, stride, padding, output_padding, bn=batch_norm):\n","            layers = [nn.ConvTranspose2d(input_channels, output_channels, kernel_size = kernel_size, stride = stride, padding = padding, output_padding = output_padding)]\n","            if bn:\n","                layers.append(nn.BatchNorm2d(output_channels, momentum = momentum))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","\n","        self.first_layer = nn.Sequential(*linear_block(latent_dim, 128 *  self.init_size**2, bn = False))\n","\n","        # formula to keep 2D images the same size FOR CONVENIENCE\n","        # https://discuss.pytorch.org/t/how-to-keep-the-shape-of-input-and-output-same-when-dilation-conv/14338/2\n","\n","        # I used this formula to keep the Image Sizes the same for deconvolutional layers\n","        # https://www.wolframalpha.com/input/?i=28+%3D+%2828+-+1%29+*+1+-2Z+%2B++P+%2B+%283-1%29+%2B+1\n","\n","        # FORMULA FOR SIZE OF CONVOLUTIONAL AND DECONV LAYERS ARE DIFFERENT\n","\n","        self.deconvolutional_part = nn.Sequential(\n","                *deconv_block(128, 128, kernel_size = 3, stride = 2, padding = 1, output_padding = 1),\n","                *deconv_block(128, 64, kernel_size = 3, stride = 2, padding = 1, output_padding = 1),\n","                *deconv_block(64, 32, kernel_size = 3, stride = 2, padding = 1, output_padding = 1),\n","                *deconv_block(32, 16, kernel_size = 3, stride = 2, padding = 1, output_padding = 1),\n","                # Taking really long to train\n","                # Very last deconv part, needs to be right size of image\n","                # channels is 1 for mnist, 3 for colored datasets\n","                # NO batch norm here, always\n","                nn.Conv2d(16, channels, 3, stride = 1, padding = 1),\n","                # Can switch to Tanh for LSGAN if needed\n","                nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        out = self.first_layer(z)\n","        out = out.view(out.shape[0], 128,  self.init_size,  self.init_size)\n","        img = self.deconvolutional_part(out)\n","        return img\n","\n","\n","class Our_Discriminator(nn.Module):\n","    def __init__(self, batch_norm = True, momentum = 0.8):\n","        super(Our_Discriminator, self).__init__()\n","\n","        def conv_block(in_filters, out_filters, kernel_size, stride, padding = 0, bn=batch_norm):\n","            block = [nn.Conv2d(in_filters, out_filters, kernel_size, stride, padding)]\n","            if bn:\n","                block.append(nn.BatchNorm2d(out_filters, momentum = momentum))\n","            block.append(nn.LeakyReLU(0.2, inplace=True))\n","            return block\n","\n","\n","        # FORMULA FOR SIZE OF CONVOLUTIONAL AND DECONV LAYERS ARE DIFFERENT\n","        # We don't have to keep image size same, but do it for convenience of knowing\n","        # size of last layer\n","        self.model = nn.Sequential(\n","            # change from kernel size from 5 to 4 to make padding an integer\n","            # and keep image size the same\n","            *conv_block(channels, 16, 3, stride = 2, padding = 1, bn = False),\n","            *conv_block(16, 32, 3, stride = 2, padding = 1),\n","            *conv_block(32, 64, 3, stride = 2, padding = 1),\n","            *conv_block(64, 128, 3, stride = 2, padding = 1),\n","            #*conv_block(128, 256, 4, stride = 2, padding = 15),\n","            #*conv_block(256, 512, 4, stride = 2, padding = 15),\n","        )\n","\n","        ds_size = img_size // 2 ** 4\n","        self.adv_layer = nn.Sequential(\n","            # Keep  Linear part only for LSGAN\n","            nn.Linear(128 * ds_size ** 2, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, img):\n","        out = self.model(img)\n","        out = out.view(out.shape[0], -1)\n","        validity = self.adv_layer(out)\n","\n","        return validity"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7Ad_6n7a6PI","colab_type":"code","colab":{}},"source":["# Loss function\n","#adversarial_loss = torch.nn.BCELoss() # GAN\n","adversarial_loss = torch.nn.MSELoss()  # LSGAN\n","\n","# Initialize generator and discriminator\n","our_generator = Our_Generator(batch_norm = True, momentum = 0.1)\n","our_discriminator = Our_Discriminator(batch_norm = True, momentum = 0.1)\n","\n","#our_generator = Generator()\n","#our_discriminator = Discriminator()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wK_HUQ1YbMyK","colab_type":"code","colab":{}},"source":["if cuda:\n","    our_generator.cuda()\n","    our_discriminator.cuda()\n","    adversarial_loss.cuda()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"79wggt1SmcuA","colab_type":"code","colab":{}},"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","our_generator.apply(weights_init_normal)\n","our_discriminator.apply(weights_init_normal)\n","\n","# pearson chi-squared minimiation\n","#a = -1 \n","#b = 1\n","#c = 0\n","# values from paper are\n","a = 0\n","b = 1\n","c = 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HALuWYv1bU15","colab_type":"code","colab":{}},"source":["fashion_dataloader = torch.utils.data.DataLoader(\n","    datasets.FashionMNIST(\n","        BASE_DIR + '/data/fashion-mnist/train',\n","        train=True,\n","        download=True,\n","        transform=transforms.Compose(\n","            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n","        ),\n","    ),\n","    batch_size=batch_size,\n","    shuffle=True,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Grhu_SxTbYU-","colab_type":"code","colab":{}},"source":["optimizer_our_G = torch.optim.Adam(our_generator.parameters(), lr=lr, betas=(b1, b2))\n","optimizer_our_D = torch.optim.Adam(our_discriminator.parameters(), lr=lr, betas=(b1, b2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGfppJ2jbb2p","colab_type":"code","colab":{}},"source":["# CUDA tensor or not\n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","\n","# to fix a bug in save images\n","#listdir(BASE_DIR + \"/data/our_gan/fashion-mnist/images/\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7EtpGNoMZhPI","colab_type":"code","outputId":"af192f11-9781-43e0-95e8-dd52e3b920f4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["for i, (imgs, _) in enumerate(fashion_dataloader):\n","  print(imgs.shape)\n","  break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64, 1, 32, 32])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1k3a_je35UIh","colab_type":"code","outputId":"2e1f947d-f5aa-43a7-afe8-71437fd22f7c","colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n","z = z.cpu()\n","print(z[0])\n","m = nn.BatchNorm1d(latent_dim).cpu()\n","m(z)[0]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([ 0.3011,  2.1453, -0.4487,  ..., -0.7857,  0.1149, -0.3807])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.1290,  2.2514, -0.2471,  ..., -0.7858,  0.1812, -0.3764],\n","       grad_fn=<SelectBackward>)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"yfRjDbkHl3gX","colab_type":"code","outputId":"ae280b4a-a12f-4e93-9fa3-5972bff0148a","colab":{"base_uri":"https://localhost:8080/","height":399}},"source":["our_generator"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Our_Generator(\n","  (first_layer): Sequential(\n","    (0): Linear(in_features=1024, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","  )\n","  (deconvolutional_part): Sequential(\n","    (0): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (6): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (9): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n","    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (12): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"il3CLCykl5cn","colab_type":"code","outputId":"d352ec48-5718-40b0-c2bc-b2a702241eb8","colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["our_discriminator"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Our_Discriminator(\n","  (model): Sequential(\n","    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n","    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n","  )\n","  (adv_layer): Sequential(\n","    (0): Linear(in_features=512, out_features=1, bias=True)\n","    (1): Sigmoid()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"dThhO_f-bhnh","colab_type":"code","outputId":"21ae17c6-9f1e-4b64-da1b-0e08a84f6cd6","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# ----------\n","#  Training\n","# ----------\n","start_time = time.time()\n","for epoch in range(n_epochs):\n","    for i, (imgs, _) in enumerate(fashion_dataloader):\n","\n","        # Adversarial ground truths\n","\n","        # a and c are used on the fake data\n","        # b is used on the real data\n","        # a\n","\n","        # this is what it was before\n","        # valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n","        # fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n","\n","        fake_a_loss_value = Variable(Tensor(imgs.size(0), 1).fill_(a), requires_grad=False)\n","        valid_b_loss_value = Variable(Tensor(imgs.size(0), 1).fill_(b), requires_grad=False)\n","        valid_c_loss_value = Variable(Tensor(imgs.size(0), 1).fill_(c), requires_grad=False)\n","\n","        # Configure input\n","        real_imgs = Variable(imgs.type(Tensor))\n","\n","        # -----------------\n","        #  Train Generator\n","        # -----------------\n","\n","        optimizer_our_G.zero_grad()\n","\n","        # Sample noise as generator input\n","        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n","\n","        # Generate a batch of images\n","        gen_imgs = our_generator(z)\n","\n","        # Loss measures generator's ability to fool the discriminator\n","        # this is what it was before\n","        # g_loss = adversarial_loss(our_discriminator(gen_imgs), valid)\n","        g_loss = 0.5 * adversarial_loss(our_discriminator(gen_imgs), valid_c_loss_value)\n","        g_loss.backward()\n","        optimizer_our_G.step()\n","\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","\n","        optimizer_our_D.zero_grad()\n","\n","        # Measure discriminator's ability to classify real from generated samples\n","        # this is what it was before\n","        # real_loss = adversarial_loss(our_discriminator(real_imgs), valid)\n","        # fake_loss = adversarial_loss(our_discriminator(gen_imgs.detach()), fake)\n","\n","        real_loss = adversarial_loss(our_discriminator(real_imgs), valid_b_loss_value)\n","        fake_loss = adversarial_loss(our_discriminator(gen_imgs.detach()), fake_a_loss_value)\n","        d_loss = (real_loss + fake_loss) / 2\n","\n","        d_loss.backward()\n","        optimizer_our_D.step()\n","        if i % 400 == 0: \n","            print(\n","                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n","                % (epoch, n_epochs, i, len(fashion_dataloader), d_loss.item(), g_loss.item())\n","            )\n","\n","        batches_done = epoch * len(fashion_dataloader) + i\n","        if batches_done % sample_interval == 0:\n","            save_image(gen_imgs.data[:25], BASE_DIR + \"/data/lsgan/momentum-0.1-batch-fashion-mnist/images_momentum/%d.png\" % batches_done, nrow=5, normalize=False)\n","\n","\n","end_time = time.time()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[Epoch 0/200] [Batch 0/938] [D loss: 0.302936] [G loss: 0.065185]\n","[Epoch 0/200] [Batch 400/938] [D loss: 0.125348] [G loss: 0.352319]\n","[Epoch 0/200] [Batch 800/938] [D loss: 0.090600] [G loss: 0.274151]\n","[Epoch 1/200] [Batch 0/938] [D loss: 0.165010] [G loss: 0.159278]\n","[Epoch 1/200] [Batch 400/938] [D loss: 0.147912] [G loss: 0.267190]\n","[Epoch 1/200] [Batch 800/938] [D loss: 0.155215] [G loss: 0.172287]\n","[Epoch 2/200] [Batch 0/938] [D loss: 0.181950] [G loss: 0.201151]\n","[Epoch 2/200] [Batch 400/938] [D loss: 0.119987] [G loss: 0.281299]\n","[Epoch 2/200] [Batch 800/938] [D loss: 0.128620] [G loss: 0.211219]\n","[Epoch 3/200] [Batch 0/938] [D loss: 0.090669] [G loss: 0.315005]\n","[Epoch 3/200] [Batch 400/938] [D loss: 0.080065] [G loss: 0.261887]\n","[Epoch 3/200] [Batch 800/938] [D loss: 0.227286] [G loss: 0.392128]\n","[Epoch 4/200] [Batch 0/938] [D loss: 0.043576] [G loss: 0.304266]\n","[Epoch 4/200] [Batch 400/938] [D loss: 0.023649] [G loss: 0.342862]\n","[Epoch 4/200] [Batch 800/938] [D loss: 0.013449] [G loss: 0.468187]\n","[Epoch 5/200] [Batch 0/938] [D loss: 0.008395] [G loss: 0.449333]\n","[Epoch 5/200] [Batch 400/938] [D loss: 0.000702] [G loss: 0.474524]\n","[Epoch 5/200] [Batch 800/938] [D loss: 0.004222] [G loss: 0.488641]\n","[Epoch 6/200] [Batch 0/938] [D loss: 0.004141] [G loss: 0.457483]\n","[Epoch 6/200] [Batch 400/938] [D loss: 0.499985] [G loss: 0.499995]\n","[Epoch 6/200] [Batch 800/938] [D loss: 0.487391] [G loss: 0.497420]\n","[Epoch 7/200] [Batch 0/938] [D loss: 0.018657] [G loss: 0.359115]\n","[Epoch 7/200] [Batch 400/938] [D loss: 0.028797] [G loss: 0.382496]\n","[Epoch 7/200] [Batch 800/938] [D loss: 0.000789] [G loss: 0.473226]\n","[Epoch 8/200] [Batch 0/938] [D loss: 0.032805] [G loss: 0.383067]\n","[Epoch 8/200] [Batch 400/938] [D loss: 0.000055] [G loss: 0.499383]\n","[Epoch 8/200] [Batch 800/938] [D loss: 0.076566] [G loss: 0.421124]\n","[Epoch 9/200] [Batch 0/938] [D loss: 0.114962] [G loss: 0.474583]\n","[Epoch 9/200] [Batch 400/938] [D loss: 0.000183] [G loss: 0.490023]\n","[Epoch 9/200] [Batch 800/938] [D loss: 0.000020] [G loss: 0.499662]\n","[Epoch 10/200] [Batch 0/938] [D loss: 0.053007] [G loss: 0.345911]\n","[Epoch 10/200] [Batch 400/938] [D loss: 0.000037] [G loss: 0.499674]\n","[Epoch 10/200] [Batch 800/938] [D loss: 0.000039] [G loss: 0.499330]\n","[Epoch 11/200] [Batch 0/938] [D loss: 0.050264] [G loss: 0.308493]\n","[Epoch 11/200] [Batch 400/938] [D loss: 0.015669] [G loss: 0.396992]\n","[Epoch 11/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499760]\n","[Epoch 12/200] [Batch 0/938] [D loss: 0.000006] [G loss: 0.499450]\n","[Epoch 12/200] [Batch 400/938] [D loss: 0.028980] [G loss: 0.323540]\n","[Epoch 12/200] [Batch 800/938] [D loss: 0.000116] [G loss: 0.498372]\n","[Epoch 13/200] [Batch 0/938] [D loss: 0.000080] [G loss: 0.499604]\n","[Epoch 13/200] [Batch 400/938] [D loss: 0.087258] [G loss: 0.242169]\n","[Epoch 13/200] [Batch 800/938] [D loss: 0.001031] [G loss: 0.471260]\n","[Epoch 14/200] [Batch 0/938] [D loss: 0.001141] [G loss: 0.465216]\n","[Epoch 14/200] [Batch 400/938] [D loss: 0.000272] [G loss: 0.498321]\n","[Epoch 14/200] [Batch 800/938] [D loss: 0.024011] [G loss: 0.340015]\n","[Epoch 15/200] [Batch 0/938] [D loss: 0.000255] [G loss: 0.492799]\n","[Epoch 15/200] [Batch 400/938] [D loss: 0.011576] [G loss: 0.392479]\n","[Epoch 15/200] [Batch 800/938] [D loss: 0.027935] [G loss: 0.329226]\n","[Epoch 16/200] [Batch 0/938] [D loss: 0.000135] [G loss: 0.489624]\n","[Epoch 16/200] [Batch 400/938] [D loss: 0.033935] [G loss: 0.329313]\n","[Epoch 16/200] [Batch 800/938] [D loss: 0.000086] [G loss: 0.499814]\n","[Epoch 17/200] [Batch 0/938] [D loss: 0.000348] [G loss: 0.490814]\n","[Epoch 17/200] [Batch 400/938] [D loss: 0.314324] [G loss: 0.348277]\n","[Epoch 17/200] [Batch 800/938] [D loss: 0.000097] [G loss: 0.491703]\n","[Epoch 18/200] [Batch 0/938] [D loss: 0.003612] [G loss: 0.441063]\n","[Epoch 18/200] [Batch 400/938] [D loss: 0.000446] [G loss: 0.480860]\n","[Epoch 18/200] [Batch 800/938] [D loss: 0.012290] [G loss: 0.464942]\n","[Epoch 19/200] [Batch 0/938] [D loss: 0.000251] [G loss: 0.495375]\n","[Epoch 19/200] [Batch 400/938] [D loss: 0.000007] [G loss: 0.499095]\n","[Epoch 19/200] [Batch 800/938] [D loss: 0.000011] [G loss: 0.496914]\n","[Epoch 20/200] [Batch 0/938] [D loss: 0.000044] [G loss: 0.498048]\n","[Epoch 20/200] [Batch 400/938] [D loss: 0.214070] [G loss: 0.489389]\n","[Epoch 20/200] [Batch 800/938] [D loss: 0.000970] [G loss: 0.470251]\n","[Epoch 21/200] [Batch 0/938] [D loss: 0.000213] [G loss: 0.487674]\n","[Epoch 21/200] [Batch 400/938] [D loss: 0.000053] [G loss: 0.498045]\n","[Epoch 21/200] [Batch 800/938] [D loss: 0.116532] [G loss: 0.472444]\n","[Epoch 22/200] [Batch 0/938] [D loss: 0.015935] [G loss: 0.388719]\n","[Epoch 22/200] [Batch 400/938] [D loss: 0.017557] [G loss: 0.397252]\n","[Epoch 22/200] [Batch 800/938] [D loss: 0.000055] [G loss: 0.499814]\n","[Epoch 23/200] [Batch 0/938] [D loss: 0.031290] [G loss: 0.405129]\n","[Epoch 23/200] [Batch 400/938] [D loss: 0.001132] [G loss: 0.499776]\n","[Epoch 23/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499838]\n","[Epoch 24/200] [Batch 0/938] [D loss: 0.000010] [G loss: 0.499192]\n","[Epoch 24/200] [Batch 400/938] [D loss: 0.000003] [G loss: 0.499795]\n","[Epoch 24/200] [Batch 800/938] [D loss: 0.065781] [G loss: 0.265090]\n","[Epoch 25/200] [Batch 0/938] [D loss: 0.000028] [G loss: 0.499589]\n","[Epoch 25/200] [Batch 400/938] [D loss: 0.000004] [G loss: 0.499677]\n","[Epoch 25/200] [Batch 800/938] [D loss: 0.005592] [G loss: 0.421983]\n","[Epoch 26/200] [Batch 0/938] [D loss: 0.000041] [G loss: 0.499381]\n","[Epoch 26/200] [Batch 400/938] [D loss: 0.000018] [G loss: 0.499926]\n","[Epoch 26/200] [Batch 800/938] [D loss: 0.000759] [G loss: 0.480294]\n","[Epoch 27/200] [Batch 0/938] [D loss: 0.002364] [G loss: 0.452569]\n","[Epoch 27/200] [Batch 400/938] [D loss: 0.000003] [G loss: 0.499960]\n","[Epoch 27/200] [Batch 800/938] [D loss: 0.000004] [G loss: 0.499954]\n","[Epoch 28/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499927]\n","[Epoch 28/200] [Batch 400/938] [D loss: 0.256057] [G loss: 0.411763]\n","[Epoch 28/200] [Batch 800/938] [D loss: 0.001850] [G loss: 0.455407]\n","[Epoch 29/200] [Batch 0/938] [D loss: 0.000021] [G loss: 0.496251]\n","[Epoch 29/200] [Batch 400/938] [D loss: 0.000425] [G loss: 0.499750]\n","[Epoch 29/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499602]\n","[Epoch 30/200] [Batch 0/938] [D loss: 0.000005] [G loss: 0.499832]\n","[Epoch 30/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499926]\n","[Epoch 30/200] [Batch 800/938] [D loss: 0.000017] [G loss: 0.499927]\n","[Epoch 31/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499856]\n","[Epoch 31/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499904]\n","[Epoch 31/200] [Batch 800/938] [D loss: 0.499437] [G loss: 0.499989]\n","[Epoch 32/200] [Batch 0/938] [D loss: 0.016454] [G loss: 0.373092]\n","[Epoch 32/200] [Batch 400/938] [D loss: 0.000604] [G loss: 0.499576]\n","[Epoch 32/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499551]\n","[Epoch 33/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.498885]\n","[Epoch 33/200] [Batch 400/938] [D loss: 0.000314] [G loss: 0.487235]\n","[Epoch 33/200] [Batch 800/938] [D loss: 0.000017] [G loss: 0.499891]\n","[Epoch 34/200] [Batch 0/938] [D loss: 0.002688] [G loss: 0.456284]\n","[Epoch 34/200] [Batch 400/938] [D loss: 0.001091] [G loss: 0.486126]\n","[Epoch 34/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499955]\n","[Epoch 35/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499853]\n","[Epoch 35/200] [Batch 400/938] [D loss: 0.000030] [G loss: 0.499712]\n","[Epoch 35/200] [Batch 800/938] [D loss: 0.030859] [G loss: 0.446419]\n","[Epoch 36/200] [Batch 0/938] [D loss: 0.010987] [G loss: 0.418029]\n","[Epoch 36/200] [Batch 400/938] [D loss: 0.000023] [G loss: 0.496885]\n","[Epoch 36/200] [Batch 800/938] [D loss: 0.001029] [G loss: 0.473658]\n","[Epoch 37/200] [Batch 0/938] [D loss: 0.000006] [G loss: 0.497763]\n","[Epoch 37/200] [Batch 400/938] [D loss: 0.011134] [G loss: 0.415402]\n","[Epoch 37/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499843]\n","[Epoch 38/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.498837]\n","[Epoch 38/200] [Batch 400/938] [D loss: 0.002095] [G loss: 0.457188]\n","[Epoch 38/200] [Batch 800/938] [D loss: 0.008805] [G loss: 0.407131]\n","[Epoch 39/200] [Batch 0/938] [D loss: 0.000021] [G loss: 0.499794]\n","[Epoch 39/200] [Batch 400/938] [D loss: 0.025108] [G loss: 0.346554]\n","[Epoch 39/200] [Batch 800/938] [D loss: 0.000008] [G loss: 0.499087]\n","[Epoch 40/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499927]\n","[Epoch 40/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499963]\n","[Epoch 40/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499809]\n","[Epoch 41/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499514]\n","[Epoch 41/200] [Batch 400/938] [D loss: 0.000021] [G loss: 0.498265]\n","[Epoch 41/200] [Batch 800/938] [D loss: 0.280944] [G loss: 0.370213]\n","[Epoch 42/200] [Batch 0/938] [D loss: 0.009145] [G loss: 0.428366]\n","[Epoch 42/200] [Batch 400/938] [D loss: 0.082156] [G loss: 0.359164]\n","[Epoch 42/200] [Batch 800/938] [D loss: 0.000022] [G loss: 0.499906]\n","[Epoch 43/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499689]\n","[Epoch 43/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499819]\n","[Epoch 43/200] [Batch 800/938] [D loss: 0.000019] [G loss: 0.499491]\n","[Epoch 44/200] [Batch 0/938] [D loss: 0.003870] [G loss: 0.431330]\n","[Epoch 44/200] [Batch 400/938] [D loss: 0.000324] [G loss: 0.482369]\n","[Epoch 44/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499979]\n","[Epoch 45/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499946]\n","[Epoch 45/200] [Batch 400/938] [D loss: 0.004364] [G loss: 0.454418]\n","[Epoch 45/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499701]\n","[Epoch 46/200] [Batch 0/938] [D loss: 0.014333] [G loss: 0.499287]\n","[Epoch 46/200] [Batch 400/938] [D loss: 0.000004] [G loss: 0.499795]\n","[Epoch 46/200] [Batch 800/938] [D loss: 0.225701] [G loss: 0.082620]\n","[Epoch 47/200] [Batch 0/938] [D loss: 0.004593] [G loss: 0.444060]\n","[Epoch 47/200] [Batch 400/938] [D loss: 0.000012] [G loss: 0.499915]\n","[Epoch 47/200] [Batch 800/938] [D loss: 0.000004] [G loss: 0.499940]\n","[Epoch 48/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499809]\n","[Epoch 48/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499867]\n","[Epoch 48/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499646]\n","[Epoch 49/200] [Batch 0/938] [D loss: 0.000016] [G loss: 0.499896]\n","[Epoch 49/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499962]\n","[Epoch 49/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499911]\n","[Epoch 50/200] [Batch 0/938] [D loss: 0.000013] [G loss: 0.499892]\n","[Epoch 50/200] [Batch 400/938] [D loss: 0.000003] [G loss: 0.499847]\n","[Epoch 50/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499678]\n","[Epoch 51/200] [Batch 0/938] [D loss: 0.000007] [G loss: 0.499710]\n","[Epoch 51/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499842]\n","[Epoch 51/200] [Batch 800/938] [D loss: 0.000019] [G loss: 0.499803]\n","[Epoch 52/200] [Batch 0/938] [D loss: 0.000031] [G loss: 0.499909]\n","[Epoch 52/200] [Batch 400/938] [D loss: 0.000140] [G loss: 0.499191]\n","[Epoch 52/200] [Batch 800/938] [D loss: 0.000295] [G loss: 0.481593]\n","[Epoch 53/200] [Batch 0/938] [D loss: 0.013991] [G loss: 0.466720]\n","[Epoch 53/200] [Batch 400/938] [D loss: 0.000034] [G loss: 0.499541]\n","[Epoch 53/200] [Batch 800/938] [D loss: 0.000004] [G loss: 0.499686]\n","[Epoch 54/200] [Batch 0/938] [D loss: 0.000092] [G loss: 0.491957]\n","[Epoch 54/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499845]\n","[Epoch 54/200] [Batch 800/938] [D loss: 0.024483] [G loss: 0.394546]\n","[Epoch 55/200] [Batch 0/938] [D loss: 0.000100] [G loss: 0.499005]\n","[Epoch 55/200] [Batch 400/938] [D loss: 0.499728] [G loss: 0.499998]\n","[Epoch 55/200] [Batch 800/938] [D loss: 0.000025] [G loss: 0.499482]\n","[Epoch 56/200] [Batch 0/938] [D loss: 0.000911] [G loss: 0.472755]\n","[Epoch 56/200] [Batch 400/938] [D loss: 0.000013] [G loss: 0.499987]\n","[Epoch 56/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499984]\n","[Epoch 57/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499966]\n","[Epoch 57/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499931]\n","[Epoch 57/200] [Batch 800/938] [D loss: 0.000028] [G loss: 0.498415]\n","[Epoch 58/200] [Batch 0/938] [D loss: 0.000090] [G loss: 0.499915]\n","[Epoch 58/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499944]\n","[Epoch 58/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499982]\n","[Epoch 59/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499981]\n","[Epoch 59/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499871]\n","[Epoch 59/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499895]\n","[Epoch 60/200] [Batch 0/938] [D loss: 0.000005] [G loss: 0.499925]\n","[Epoch 60/200] [Batch 400/938] [D loss: 0.000009] [G loss: 0.499944]\n","[Epoch 60/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499819]\n","[Epoch 61/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499926]\n","[Epoch 61/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499998]\n","[Epoch 61/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499998]\n","[Epoch 62/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 62/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499995]\n","[Epoch 62/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 63/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499992]\n","[Epoch 63/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499990]\n","[Epoch 63/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499986]\n","[Epoch 64/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499728]\n","[Epoch 64/200] [Batch 400/938] [D loss: 0.000602] [G loss: 0.474244]\n","[Epoch 64/200] [Batch 800/938] [D loss: 0.000007] [G loss: 0.498776]\n","[Epoch 65/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499632]\n","[Epoch 65/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499983]\n","[Epoch 65/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499940]\n","[Epoch 66/200] [Batch 0/938] [D loss: 0.267630] [G loss: 0.104232]\n","[Epoch 66/200] [Batch 400/938] [D loss: 0.002183] [G loss: 0.452621]\n","[Epoch 66/200] [Batch 800/938] [D loss: 0.000022] [G loss: 0.496294]\n","[Epoch 67/200] [Batch 0/938] [D loss: 0.000006] [G loss: 0.498791]\n","[Epoch 67/200] [Batch 400/938] [D loss: 0.000037] [G loss: 0.499890]\n","[Epoch 67/200] [Batch 800/938] [D loss: 0.006926] [G loss: 0.450781]\n","[Epoch 68/200] [Batch 0/938] [D loss: 0.000058] [G loss: 0.499546]\n","[Epoch 68/200] [Batch 400/938] [D loss: 0.336717] [G loss: 0.495977]\n","[Epoch 68/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499642]\n","[Epoch 69/200] [Batch 0/938] [D loss: 0.000176] [G loss: 0.498903]\n","[Epoch 69/200] [Batch 400/938] [D loss: 0.000067] [G loss: 0.493690]\n","[Epoch 69/200] [Batch 800/938] [D loss: 0.000006] [G loss: 0.499976]\n","[Epoch 70/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499929]\n","[Epoch 70/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499584]\n","[Epoch 70/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499906]\n","[Epoch 71/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499929]\n","[Epoch 71/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499921]\n","[Epoch 71/200] [Batch 800/938] [D loss: 0.020873] [G loss: 0.348645]\n","[Epoch 72/200] [Batch 0/938] [D loss: 0.000341] [G loss: 0.480792]\n","[Epoch 72/200] [Batch 400/938] [D loss: 0.000024] [G loss: 0.499855]\n","[Epoch 72/200] [Batch 800/938] [D loss: 0.000762] [G loss: 0.467851]\n","[Epoch 73/200] [Batch 0/938] [D loss: 0.000007] [G loss: 0.499848]\n","[Epoch 73/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499235]\n","[Epoch 73/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499967]\n","[Epoch 74/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499901]\n","[Epoch 74/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499974]\n","[Epoch 74/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499944]\n","[Epoch 75/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499798]\n","[Epoch 75/200] [Batch 400/938] [D loss: 0.000002] [G loss: 0.499230]\n","[Epoch 75/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499874]\n","[Epoch 76/200] [Batch 0/938] [D loss: 0.045456] [G loss: 0.326936]\n","[Epoch 76/200] [Batch 400/938] [D loss: 0.000020] [G loss: 0.499958]\n","[Epoch 76/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499667]\n","[Epoch 77/200] [Batch 0/938] [D loss: 0.000019] [G loss: 0.499841]\n","[Epoch 77/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499915]\n","[Epoch 77/200] [Batch 800/938] [D loss: 0.000583] [G loss: 0.485538]\n","[Epoch 78/200] [Batch 0/938] [D loss: 0.000037] [G loss: 0.499779]\n","[Epoch 78/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499990]\n","[Epoch 78/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499976]\n","[Epoch 79/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499979]\n","[Epoch 79/200] [Batch 400/938] [D loss: 0.000004] [G loss: 0.499502]\n","[Epoch 79/200] [Batch 800/938] [D loss: 0.006469] [G loss: 0.444667]\n","[Epoch 80/200] [Batch 0/938] [D loss: 0.001326] [G loss: 0.463715]\n","[Epoch 80/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499990]\n","[Epoch 80/200] [Batch 800/938] [D loss: 0.000008] [G loss: 0.499895]\n","[Epoch 81/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499932]\n","[Epoch 81/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499988]\n","[Epoch 81/200] [Batch 800/938] [D loss: 0.000023] [G loss: 0.499836]\n","[Epoch 82/200] [Batch 0/938] [D loss: 0.020913] [G loss: 0.499175]\n","[Epoch 82/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499892]\n","[Epoch 82/200] [Batch 800/938] [D loss: 0.000017] [G loss: 0.499326]\n","[Epoch 83/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499452]\n","[Epoch 83/200] [Batch 400/938] [D loss: 0.000010] [G loss: 0.499623]\n","[Epoch 83/200] [Batch 800/938] [D loss: 0.000017] [G loss: 0.498155]\n","[Epoch 84/200] [Batch 0/938] [D loss: 0.000140] [G loss: 0.498845]\n","[Epoch 84/200] [Batch 400/938] [D loss: 0.010525] [G loss: 0.484271]\n","[Epoch 84/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499880]\n","[Epoch 85/200] [Batch 0/938] [D loss: 0.000056] [G loss: 0.492097]\n","[Epoch 85/200] [Batch 400/938] [D loss: 0.000049] [G loss: 0.499650]\n","[Epoch 85/200] [Batch 800/938] [D loss: 0.000025] [G loss: 0.495564]\n","[Epoch 86/200] [Batch 0/938] [D loss: 0.000045] [G loss: 0.499067]\n","[Epoch 86/200] [Batch 400/938] [D loss: 0.000011] [G loss: 0.499985]\n","[Epoch 86/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499812]\n","[Epoch 87/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499991]\n","[Epoch 87/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499527]\n","[Epoch 87/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499392]\n","[Epoch 88/200] [Batch 0/938] [D loss: 0.004061] [G loss: 0.441027]\n","[Epoch 88/200] [Batch 400/938] [D loss: 0.000003] [G loss: 0.499736]\n","[Epoch 88/200] [Batch 800/938] [D loss: 0.000004] [G loss: 0.499543]\n","[Epoch 89/200] [Batch 0/938] [D loss: 0.000835] [G loss: 0.499951]\n","[Epoch 89/200] [Batch 400/938] [D loss: 0.000010] [G loss: 0.499981]\n","[Epoch 89/200] [Batch 800/938] [D loss: 0.000091] [G loss: 0.488595]\n","[Epoch 90/200] [Batch 0/938] [D loss: 0.497907] [G loss: 0.000020]\n","[Epoch 90/200] [Batch 400/938] [D loss: 0.081945] [G loss: 0.266519]\n","[Epoch 90/200] [Batch 800/938] [D loss: 0.000294] [G loss: 0.499824]\n","[Epoch 91/200] [Batch 0/938] [D loss: 0.000043] [G loss: 0.499903]\n","[Epoch 91/200] [Batch 400/938] [D loss: 0.001585] [G loss: 0.466050]\n","[Epoch 91/200] [Batch 800/938] [D loss: 0.001060] [G loss: 0.499935]\n","[Epoch 92/200] [Batch 0/938] [D loss: 0.001593] [G loss: 0.461127]\n","[Epoch 92/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499983]\n","[Epoch 92/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499919]\n","[Epoch 93/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499930]\n","[Epoch 93/200] [Batch 400/938] [D loss: 0.000414] [G loss: 0.493415]\n","[Epoch 93/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499688]\n","[Epoch 94/200] [Batch 0/938] [D loss: 0.000008] [G loss: 0.499971]\n","[Epoch 94/200] [Batch 400/938] [D loss: 0.000138] [G loss: 0.499824]\n","[Epoch 94/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499977]\n","[Epoch 95/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499983]\n","[Epoch 95/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499961]\n","[Epoch 95/200] [Batch 800/938] [D loss: 0.000021] [G loss: 0.499792]\n","[Epoch 96/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499788]\n","[Epoch 96/200] [Batch 400/938] [D loss: 0.000013] [G loss: 0.499987]\n","[Epoch 96/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499960]\n","[Epoch 97/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499870]\n","[Epoch 97/200] [Batch 400/938] [D loss: 0.000047] [G loss: 0.499384]\n","[Epoch 97/200] [Batch 800/938] [D loss: 0.000006] [G loss: 0.499670]\n","[Epoch 98/200] [Batch 0/938] [D loss: 0.000061] [G loss: 0.499928]\n","[Epoch 98/200] [Batch 400/938] [D loss: 0.001926] [G loss: 0.456681]\n","[Epoch 98/200] [Batch 800/938] [D loss: 0.000015] [G loss: 0.499321]\n","[Epoch 99/200] [Batch 0/938] [D loss: 0.000079] [G loss: 0.499964]\n","[Epoch 99/200] [Batch 400/938] [D loss: 0.000014] [G loss: 0.499032]\n","[Epoch 99/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499966]\n","[Epoch 100/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499888]\n","[Epoch 100/200] [Batch 400/938] [D loss: 0.000039] [G loss: 0.499926]\n","[Epoch 100/200] [Batch 800/938] [D loss: 0.000013] [G loss: 0.499963]\n","[Epoch 101/200] [Batch 0/938] [D loss: 0.000005] [G loss: 0.499059]\n","[Epoch 101/200] [Batch 400/938] [D loss: 0.000007] [G loss: 0.499960]\n","[Epoch 101/200] [Batch 800/938] [D loss: 0.000033] [G loss: 0.499993]\n","[Epoch 102/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499997]\n","[Epoch 102/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499991]\n","[Epoch 102/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499994]\n","[Epoch 103/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499995]\n","[Epoch 103/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499990]\n","[Epoch 103/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499992]\n","[Epoch 104/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499961]\n","[Epoch 104/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499769]\n","[Epoch 104/200] [Batch 800/938] [D loss: 0.000111] [G loss: 0.498911]\n","[Epoch 105/200] [Batch 0/938] [D loss: 0.000027] [G loss: 0.499828]\n","[Epoch 105/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499945]\n","[Epoch 105/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.498978]\n","[Epoch 106/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499988]\n","[Epoch 106/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499986]\n","[Epoch 106/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499943]\n","[Epoch 107/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499940]\n","[Epoch 107/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499927]\n","[Epoch 107/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499955]\n","[Epoch 108/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499809]\n","[Epoch 108/200] [Batch 400/938] [D loss: 0.001920] [G loss: 0.466388]\n","[Epoch 108/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499608]\n","[Epoch 109/200] [Batch 0/938] [D loss: 0.000007] [G loss: 0.499971]\n","[Epoch 109/200] [Batch 400/938] [D loss: 0.000004] [G loss: 0.499984]\n","[Epoch 109/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499955]\n","[Epoch 110/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499972]\n","[Epoch 110/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499989]\n","[Epoch 110/200] [Batch 800/938] [D loss: 0.000040] [G loss: 0.494788]\n","[Epoch 111/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499797]\n","[Epoch 111/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499395]\n","[Epoch 111/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499988]\n","[Epoch 112/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499987]\n","[Epoch 112/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499985]\n","[Epoch 112/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499988]\n","[Epoch 113/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499980]\n","[Epoch 113/200] [Batch 400/938] [D loss: 0.001986] [G loss: 0.464505]\n","[Epoch 113/200] [Batch 800/938] [D loss: 0.000850] [G loss: 0.476415]\n","[Epoch 114/200] [Batch 0/938] [D loss: 0.110565] [G loss: 0.222267]\n","[Epoch 114/200] [Batch 400/938] [D loss: 0.000034] [G loss: 0.497744]\n","[Epoch 114/200] [Batch 800/938] [D loss: 0.000030] [G loss: 0.499654]\n","[Epoch 115/200] [Batch 0/938] [D loss: 0.000029] [G loss: 0.499934]\n","[Epoch 115/200] [Batch 400/938] [D loss: 0.000009] [G loss: 0.499939]\n","[Epoch 115/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499957]\n","[Epoch 116/200] [Batch 0/938] [D loss: 0.000017] [G loss: 0.499811]\n","[Epoch 116/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499973]\n","[Epoch 116/200] [Batch 800/938] [D loss: 0.000299] [G loss: 0.495596]\n","[Epoch 117/200] [Batch 0/938] [D loss: 0.000025] [G loss: 0.499198]\n","[Epoch 117/200] [Batch 400/938] [D loss: 0.001224] [G loss: 0.466097]\n","[Epoch 117/200] [Batch 800/938] [D loss: 0.000568] [G loss: 0.484232]\n","[Epoch 118/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499889]\n","[Epoch 118/200] [Batch 400/938] [D loss: 0.000294] [G loss: 0.484972]\n","[Epoch 118/200] [Batch 800/938] [D loss: 0.000009] [G loss: 0.499007]\n","[Epoch 119/200] [Batch 0/938] [D loss: 0.000364] [G loss: 0.499998]\n","[Epoch 119/200] [Batch 400/938] [D loss: 0.000835] [G loss: 0.465703]\n","[Epoch 119/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499825]\n","[Epoch 120/200] [Batch 0/938] [D loss: 0.000004] [G loss: 0.499995]\n","[Epoch 120/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499984]\n","[Epoch 120/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499994]\n","[Epoch 121/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499995]\n","[Epoch 121/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499993]\n","[Epoch 121/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499961]\n","[Epoch 122/200] [Batch 0/938] [D loss: 0.000023] [G loss: 0.499995]\n","[Epoch 122/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499985]\n","[Epoch 122/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.498424]\n","[Epoch 123/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499974]\n","[Epoch 123/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499854]\n","[Epoch 123/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499999]\n","[Epoch 124/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499998]\n","[Epoch 124/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499998]\n","[Epoch 124/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499998]\n","[Epoch 125/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499997]\n","[Epoch 125/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499989]\n","[Epoch 125/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499975]\n","[Epoch 126/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499920]\n","[Epoch 126/200] [Batch 400/938] [D loss: 0.002688] [G loss: 0.448946]\n","[Epoch 126/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499968]\n","[Epoch 127/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499947]\n","[Epoch 127/200] [Batch 400/938] [D loss: 0.017945] [G loss: 0.486851]\n","[Epoch 127/200] [Batch 800/938] [D loss: 0.000021] [G loss: 0.499985]\n","[Epoch 128/200] [Batch 0/938] [D loss: 0.000009] [G loss: 0.499986]\n","[Epoch 128/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499819]\n","[Epoch 128/200] [Batch 800/938] [D loss: 0.000075] [G loss: 0.493844]\n","[Epoch 129/200] [Batch 0/938] [D loss: 0.000013] [G loss: 0.499994]\n","[Epoch 129/200] [Batch 400/938] [D loss: 0.007546] [G loss: 0.410125]\n","[Epoch 129/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499823]\n","[Epoch 130/200] [Batch 0/938] [D loss: 0.028425] [G loss: 0.356718]\n","[Epoch 130/200] [Batch 400/938] [D loss: 0.000062] [G loss: 0.491588]\n","[Epoch 130/200] [Batch 800/938] [D loss: 0.000217] [G loss: 0.499994]\n","[Epoch 131/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499848]\n","[Epoch 131/200] [Batch 400/938] [D loss: 0.000003] [G loss: 0.499234]\n","[Epoch 131/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499994]\n","[Epoch 132/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499987]\n","[Epoch 132/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499941]\n","[Epoch 132/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499995]\n","[Epoch 133/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499993]\n","[Epoch 133/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499994]\n","[Epoch 133/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499940]\n","[Epoch 134/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499981]\n","[Epoch 134/200] [Batch 400/938] [D loss: 0.000002] [G loss: 0.499971]\n","[Epoch 134/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499999]\n","[Epoch 135/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499998]\n","[Epoch 135/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499998]\n","[Epoch 135/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 136/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 136/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 136/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499992]\n","[Epoch 137/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499985]\n","[Epoch 137/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499998]\n","[Epoch 137/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 138/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 138/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499986]\n","[Epoch 138/200] [Batch 800/938] [D loss: 0.000081] [G loss: 0.492012]\n","[Epoch 139/200] [Batch 0/938] [D loss: 0.000008] [G loss: 0.499771]\n","[Epoch 139/200] [Batch 400/938] [D loss: 0.000778] [G loss: 0.486529]\n","[Epoch 139/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499876]\n","[Epoch 140/200] [Batch 0/938] [D loss: 0.000006] [G loss: 0.499430]\n","[Epoch 140/200] [Batch 400/938] [D loss: 0.000055] [G loss: 0.499683]\n","[Epoch 140/200] [Batch 800/938] [D loss: 0.000004] [G loss: 0.499986]\n","[Epoch 141/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499990]\n","[Epoch 141/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499973]\n","[Epoch 141/200] [Batch 800/938] [D loss: 0.000677] [G loss: 0.474936]\n","[Epoch 142/200] [Batch 0/938] [D loss: 0.000286] [G loss: 0.499925]\n","[Epoch 142/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499870]\n","[Epoch 142/200] [Batch 800/938] [D loss: 0.000677] [G loss: 0.472854]\n","[Epoch 143/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499840]\n","[Epoch 143/200] [Batch 400/938] [D loss: 0.000026] [G loss: 0.499873]\n","[Epoch 143/200] [Batch 800/938] [D loss: 0.000172] [G loss: 0.490269]\n","[Epoch 144/200] [Batch 0/938] [D loss: 0.000073] [G loss: 0.499577]\n","[Epoch 144/200] [Batch 400/938] [D loss: 0.000024] [G loss: 0.499031]\n","[Epoch 144/200] [Batch 800/938] [D loss: 0.000014] [G loss: 0.497729]\n","[Epoch 145/200] [Batch 0/938] [D loss: 0.000163] [G loss: 0.499991]\n","[Epoch 145/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499947]\n","[Epoch 145/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499971]\n","[Epoch 146/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499905]\n","[Epoch 146/200] [Batch 400/938] [D loss: 0.000212] [G loss: 0.491817]\n","[Epoch 146/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499966]\n","[Epoch 147/200] [Batch 0/938] [D loss: 0.000556] [G loss: 0.475126]\n","[Epoch 147/200] [Batch 400/938] [D loss: 0.000566] [G loss: 0.479196]\n","[Epoch 147/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499977]\n","[Epoch 148/200] [Batch 0/938] [D loss: 0.004380] [G loss: 0.445820]\n","[Epoch 148/200] [Batch 400/938] [D loss: 0.000007] [G loss: 0.499976]\n","[Epoch 148/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.498550]\n","[Epoch 149/200] [Batch 0/938] [D loss: 0.000014] [G loss: 0.499739]\n","[Epoch 149/200] [Batch 400/938] [D loss: 0.000008] [G loss: 0.499387]\n","[Epoch 149/200] [Batch 800/938] [D loss: 0.000034] [G loss: 0.499071]\n","[Epoch 150/200] [Batch 0/938] [D loss: 0.000010] [G loss: 0.497294]\n","[Epoch 150/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499980]\n","[Epoch 150/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499984]\n","[Epoch 151/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499957]\n","[Epoch 151/200] [Batch 400/938] [D loss: 0.000028] [G loss: 0.499708]\n","[Epoch 151/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499929]\n","[Epoch 152/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499855]\n","[Epoch 152/200] [Batch 400/938] [D loss: 0.000012] [G loss: 0.499982]\n","[Epoch 152/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499867]\n","[Epoch 153/200] [Batch 0/938] [D loss: 0.000084] [G loss: 0.490200]\n","[Epoch 153/200] [Batch 400/938] [D loss: 0.000002] [G loss: 0.499947]\n","[Epoch 153/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499275]\n","[Epoch 154/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499977]\n","[Epoch 154/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499266]\n","[Epoch 154/200] [Batch 800/938] [D loss: 0.000347] [G loss: 0.496528]\n","[Epoch 155/200] [Batch 0/938] [D loss: 0.000236] [G loss: 0.499717]\n","[Epoch 155/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499973]\n","[Epoch 155/200] [Batch 800/938] [D loss: 0.000010] [G loss: 0.499940]\n","[Epoch 156/200] [Batch 0/938] [D loss: 0.000002] [G loss: 0.499779]\n","[Epoch 156/200] [Batch 400/938] [D loss: 0.000008] [G loss: 0.497476]\n","[Epoch 156/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499877]\n","[Epoch 157/200] [Batch 0/938] [D loss: 0.000003] [G loss: 0.499971]\n","[Epoch 157/200] [Batch 400/938] [D loss: 0.000002] [G loss: 0.499947]\n","[Epoch 157/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499854]\n","[Epoch 158/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499823]\n","[Epoch 158/200] [Batch 400/938] [D loss: 0.000063] [G loss: 0.499850]\n","[Epoch 158/200] [Batch 800/938] [D loss: 0.000028] [G loss: 0.499176]\n","[Epoch 159/200] [Batch 0/938] [D loss: 0.000032] [G loss: 0.499832]\n","[Epoch 159/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499926]\n","[Epoch 159/200] [Batch 800/938] [D loss: 0.000011] [G loss: 0.497665]\n","[Epoch 160/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499990]\n","[Epoch 160/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499949]\n","[Epoch 160/200] [Batch 800/938] [D loss: 0.000059] [G loss: 0.499998]\n","[Epoch 161/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499950]\n","[Epoch 161/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499756]\n","[Epoch 161/200] [Batch 800/938] [D loss: 0.000030] [G loss: 0.499975]\n","[Epoch 162/200] [Batch 0/938] [D loss: 0.000004] [G loss: 0.499981]\n","[Epoch 162/200] [Batch 400/938] [D loss: 0.000009] [G loss: 0.498926]\n","[Epoch 162/200] [Batch 800/938] [D loss: 0.000017] [G loss: 0.499873]\n","[Epoch 163/200] [Batch 0/938] [D loss: 0.000069] [G loss: 0.499992]\n","[Epoch 163/200] [Batch 400/938] [D loss: 0.000004] [G loss: 0.499982]\n","[Epoch 163/200] [Batch 800/938] [D loss: 0.000003] [G loss: 0.499977]\n","[Epoch 164/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499968]\n","[Epoch 164/200] [Batch 400/938] [D loss: 0.000002] [G loss: 0.499995]\n","[Epoch 164/200] [Batch 800/938] [D loss: 0.000006] [G loss: 0.499991]\n","[Epoch 165/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499996]\n","[Epoch 165/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499991]\n","[Epoch 165/200] [Batch 800/938] [D loss: 0.000074] [G loss: 0.499994]\n","[Epoch 166/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499978]\n","[Epoch 166/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499989]\n","[Epoch 166/200] [Batch 800/938] [D loss: 0.000005] [G loss: 0.499981]\n","[Epoch 167/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499965]\n","[Epoch 167/200] [Batch 400/938] [D loss: 0.480770] [G loss: 0.499696]\n","[Epoch 167/200] [Batch 800/938] [D loss: 0.000017] [G loss: 0.499940]\n","[Epoch 168/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499919]\n","[Epoch 168/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499459]\n","[Epoch 168/200] [Batch 800/938] [D loss: 0.000010] [G loss: 0.499986]\n","[Epoch 169/200] [Batch 0/938] [D loss: 0.000011] [G loss: 0.499937]\n","[Epoch 169/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499674]\n","[Epoch 169/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499921]\n","[Epoch 170/200] [Batch 0/938] [D loss: 0.000069] [G loss: 0.491655]\n","[Epoch 170/200] [Batch 400/938] [D loss: 0.000513] [G loss: 0.499998]\n","[Epoch 170/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499997]\n","[Epoch 171/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499996]\n","[Epoch 171/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499993]\n","[Epoch 171/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499966]\n","[Epoch 172/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499709]\n","[Epoch 172/200] [Batch 400/938] [D loss: 0.000003] [G loss: 0.499977]\n","[Epoch 172/200] [Batch 800/938] [D loss: 0.000014] [G loss: 0.499868]\n","[Epoch 173/200] [Batch 0/938] [D loss: 0.000014] [G loss: 0.499991]\n","[Epoch 173/200] [Batch 400/938] [D loss: 0.000008] [G loss: 0.499987]\n","[Epoch 173/200] [Batch 800/938] [D loss: 0.000001] [G loss: 0.499972]\n","[Epoch 174/200] [Batch 0/938] [D loss: 0.000000] [G loss: 0.499983]\n","[Epoch 174/200] [Batch 400/938] [D loss: 0.000001] [G loss: 0.499995]\n","[Epoch 174/200] [Batch 800/938] [D loss: 0.012144] [G loss: 0.402636]\n","[Epoch 175/200] [Batch 0/938] [D loss: 0.000017] [G loss: 0.499885]\n","[Epoch 175/200] [Batch 400/938] [D loss: 0.000005] [G loss: 0.499972]\n","[Epoch 175/200] [Batch 800/938] [D loss: 0.000032] [G loss: 0.494942]\n","[Epoch 176/200] [Batch 0/938] [D loss: 0.000006] [G loss: 0.499897]\n","[Epoch 176/200] [Batch 400/938] [D loss: 0.000000] [G loss: 0.499973]\n","[Epoch 176/200] [Batch 800/938] [D loss: 0.000000] [G loss: 0.499964]\n","[Epoch 177/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499986]\n","[Epoch 177/200] [Batch 400/938] [D loss: 0.000002] [G loss: 0.499980]\n","[Epoch 177/200] [Batch 800/938] [D loss: 0.000002] [G loss: 0.499996]\n","[Epoch 178/200] [Batch 0/938] [D loss: 0.000001] [G loss: 0.499989]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ENfR9rxhzTn","colab_type":"code","colab":{}},"source":["print(\"Took this long\")\n","print(end_time - start_time)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lb_58TW8n-aS","colab_type":"code","colab":{}},"source":["# https://pytorch.org/tutorials/beginner/saving_loading_models.html\n","#listdir(BASE_DIR + \"/data/our_gan/no_batch_norm_fashion_mnist/\")\n","torch.save(our_generator.state_dict(), BASE_DIR + \"/data/lsgan/momentum-0.1-batch-fashion-mnist/generator_momentum.pt\")\n","torch.save(our_discriminator.state_dict(), BASE_DIR + \"/data/lsgan/momentum-0.1-batch-fashion-mnist/discriminator_momentum.pt\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5mTVoliZRw1","colab_type":"code","colab":{}},"source":["listdir(BASE_DIR + \"/data/lsgan/batch-fashion-mnist/\") "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fYeAa72UrH5r","colab_type":"text"},"source":["Test how we do on the last train batch"]},{"cell_type":"code","metadata":{"id":"Ws9BvCeyPe8p","colab_type":"code","outputId":"13bc60e3-939d-4565-8de0-85ceacee3356","colab":{"base_uri":"https://localhost:8080/","height":517}},"source":["our_generator = Our_Generator(batch_norm = True)\n","our_generator.load_state_dict(torch.load(BASE_DIR + \"/data/lsgan/momentum-0.1-batch-fashion-mnist/generator_momentum.pt\"))\n","our_generator.eval()\n","our_generator.cuda()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-111-7ba223058fa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mour_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOur_Generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mour_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/data/lsgan/momentum-0.1-batch-fashion-mnist/generator_momentum.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mour_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mour_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Our_Generator:\n\tMissing key(s) in state_dict: \"deconvolutional_part.7.weight\", \"deconvolutional_part.7.bias\", \"deconvolutional_part.7.running_mean\", \"deconvolutional_part.7.running_var\", \"deconvolutional_part.9.weight\", \"deconvolutional_part.9.bias\", \"deconvolutional_part.10.weight\", \"deconvolutional_part.10.bias\", \"deconvolutional_part.10.running_mean\", \"deconvolutional_part.10.running_var\", \"deconvolutional_part.12.weight\", \"deconvolutional_part.12.bias\". \n\tsize mismatch for first_layer.0.weight: copying a param with shape torch.Size([8192, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for first_layer.0.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for first_layer.1.weight: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for first_layer.1.bias: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for first_layer.1.running_mean: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for first_layer.1.running_var: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for deconvolutional_part.6.weight: copying a param with shape torch.Size([1, 64, 3, 3]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for deconvolutional_part.6.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([64])."]}]},{"cell_type":"code","metadata":{"id":"lIEwVp3tP1CL","colab_type":"code","outputId":"092cca84-a25b-46b8-dfd0-885101e055f2","colab":{"base_uri":"https://localhost:8080/","height":376}},"source":["our_discriminator = Our_Discriminator(batch_norm = True)\n","our_discriminator.load_state_dict(torch.load(BASE_DIR + \"/data/lsgan/momentum-0.1-batch-fashion-mnist/discriminator_momentum.pt\"))\n","our_discriminator.eval()\n","our_discriminator.cuda()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-112-87513bee0516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mour_discriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOur_Discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mour_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/data/lsgan/momentum-0.1-batch-fashion-mnist/discriminator_momentum.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mour_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mour_discriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Our_Discriminator:\n\tsize mismatch for model.8.weight: copying a param with shape torch.Size([128, 64, 4, 4]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 3]).\n\tsize mismatch for adv_layer.0.weight: copying a param with shape torch.Size([1, 2048]) from checkpoint, the shape in current model is torch.Size([1, 512])."]}]},{"cell_type":"code","metadata":{"id":"qnIXzXDNZ7na","colab_type":"code","colab":{}},"source":["z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"651tkEKcoSFL","colab_type":"code","outputId":"1d432fe7-fa8a-4c69-fc99-1901757f7506","colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["results_on_fake_images_batch_norm = our_discriminator(our_generator(z))\n","results_on_fake_images_batch_norm.mean()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-113-6d1b3eff7bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_on_fake_images_batch_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mour_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_on_fake_images_batch_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-99-6d8629215b36>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_size\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeconvolutional_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm"]}]},{"cell_type":"code","metadata":{"id":"oZooz3DZqbOG","colab_type":"code","colab":{}},"source":["real_imgs = Variable(imgs.type(Tensor))\n","results_on_real_images_no_batch_norm = our_discriminator(real_imgs)\n","results_on_real_images_no_batch_norm.mean()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gSKrOySqijH","colab_type":"code","colab":{}},"source":["fake_img_1 = our_generator(z)[0][0]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMnZIXw1qjHr","colab_type":"code","colab":{}},"source":["plt.imshow(fake_img_1.cpu().detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lq_jEb7dqpSX","colab_type":"code","colab":{}},"source":["fake_img_2 = our_generator(z)[1][0]\n","plt.imshow(fake_img_2.cpu().detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kwvADo7HgWz","colab_type":"code","colab":{}},"source":["fake_img_2 = our_generator(z)[2][0]\n","plt.imshow(fake_img_2.cpu().detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JtRawKpVd6FR","colab_type":"code","colab":{}},"source":["fake_img_2 = our_generator(z)[3][0]\n","plt.imshow(fake_img_2.cpu().detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7LKc3yvd77v","colab_type":"code","colab":{}},"source":["fake_img_2 = our_generator(z)[4][0]\n","plt.imshow(fake_img_2.cpu().detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"grt1PwxKd9n6","colab_type":"code","colab":{}},"source":["fake_img_2 = our_generator(z)[5][0]\n","plt.imshow(fake_img_2.cpu().detach().numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"foo45uHyfKRV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}